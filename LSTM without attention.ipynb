{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['embeddings', 'train.csv', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "e31d6e126881ee56a1de3efe02fcf309e900ef00"
   },
   "outputs": [],
   "source": [
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 100000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "522d9790478f62193ea5c315372a2ab9cbe9b27f"
   },
   "source": [
    "**Load packages and data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dba1893c267a1e7536bbf720636647d85c7e349c"
   },
   "source": [
    "**Load embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)\n",
    "\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].fillna(\"_##_\").values\n",
    "val_X = val_df[\"question_text\"].fillna(\"_##_\").values\n",
    "test_X = test_df[\"question_text\"].fillna(\"_##_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values\n",
    "#shuffling the data\n",
    "np.random.seed(2018)\n",
    "trn_idx = np.random.permutation(len(train_X))\n",
    "val_idx = np.random.permutation(len(val_X))\n",
    "\n",
    "train_X = train_X[trn_idx]\n",
    "val_X = val_X[val_idx]\n",
    "train_y = train_y[trn_idx]\n",
    "val_y = val_y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a662716cc5fbbcc0c84019a87c52332ed8912e8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "1f72c8c9573fb840ceb50a9cd4ac4e455e1c0ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-7-2ee1e87b620b>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-2ee1e87b620b>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    return model\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "\n",
    "inp = Input(shape=(maxlen,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "x = Bidirectional(CuDNNLSTM(64,return_sequences=True))(x)\n",
    "\n",
    "avg_pool = GlobalAveragePooling1D()(x)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "conc = concatenate([avg_pool, max_pool])\n",
    "conc = Dense(64, activation=\"relu\")(conc)\n",
    "conc = Dropout(0.1)(conc)\n",
    "outp = Dense(1, activation=\"sigmoid\")(conc)\n",
    "model = Model(inputs=inp, outputs=outp)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/4\n",
      "1175509/1175509 [==============================] - 168s 143us/step - loss: 0.1171 - acc: 0.9542 - val_loss: 0.1045 - val_acc: 0.9581\n",
      "Epoch 2/4\n",
      "1175509/1175509 [==============================] - 164s 140us/step - loss: 0.1017 - acc: 0.9598 - val_loss: 0.0990 - val_acc: 0.9599\n",
      "Epoch 3/4\n",
      " 443392/1175509 [==========>...................] - ETA: 1:37 - loss: 0.0946 - acc: 0.9623"
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_y, batch_size=512, epochs=4, validation_data=(val_X, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 6s 48us/step\n",
      "F1 score at threshold 0.1 is 0.6076055160885917\n",
      "F1 score at threshold 0.11 is 0.615923757425531\n",
      "F1 score at threshold 0.12 is 0.6236484129752354\n",
      "F1 score at threshold 0.13 is 0.6305313666251999\n",
      "F1 score at threshold 0.14 is 0.6381305369734226\n",
      "F1 score at threshold 0.15 is 0.6441768544903024\n",
      "F1 score at threshold 0.16 is 0.6496268656716419\n",
      "F1 score at threshold 0.17 is 0.6546384429606479\n",
      "F1 score at threshold 0.18 is 0.6596848578016911\n",
      "F1 score at threshold 0.19 is 0.6639420036004476\n",
      "F1 score at threshold 0.2 is 0.6671919629666108\n",
      "F1 score at threshold 0.21 is 0.6706204834288562\n",
      "F1 score at threshold 0.22 is 0.6725779636253715\n",
      "F1 score at threshold 0.23 is 0.674715981456009\n",
      "F1 score at threshold 0.24 is 0.677931176591799\n",
      "F1 score at threshold 0.25 is 0.679363097096472\n",
      "F1 score at threshold 0.26 is 0.6814433531172857\n",
      "F1 score at threshold 0.27 is 0.681948424068768\n",
      "F1 score at threshold 0.28 is 0.683745109598585\n",
      "F1 score at threshold 0.29 is 0.6849448410123297\n",
      "F1 score at threshold 0.3 is 0.685732998580941\n",
      "F1 score at threshold 0.31 is 0.6869176911626881\n",
      "F1 score at threshold 0.32 is 0.687538230551076\n",
      "F1 score at threshold 0.33 is 0.6881032547699214\n",
      "F1 score at threshold 0.34 is 0.6881123633686357\n",
      "F1 score at threshold 0.35 is 0.6876036839997711\n",
      "F1 score at threshold 0.36 is 0.6877634694231102\n",
      "F1 score at threshold 0.37 is 0.6871645274212368\n",
      "F1 score at threshold 0.38 is 0.6871136751633602\n",
      "F1 score at threshold 0.39 is 0.6870917943237146\n",
      "F1 score at threshold 0.4 is 0.6862416107382551\n",
      "F1 score at threshold 0.41 is 0.6859529141197119\n",
      "F1 score at threshold 0.42 is 0.6841365829821024\n",
      "F1 score at threshold 0.43 is 0.6817033339495903\n",
      "F1 score at threshold 0.44 is 0.6797483336448016\n",
      "F1 score at threshold 0.45 is 0.676895987926047\n",
      "F1 score at threshold 0.46 is 0.6736574515411502\n",
      "F1 score at threshold 0.47 is 0.6720995893223819\n",
      "F1 score at threshold 0.48 is 0.6699928724162509\n",
      "F1 score at threshold 0.49 is 0.6678872686850192\n",
      "F1 score at threshold 0.5 is 0.6658301413287545\n"
     ]
    }
   ],
   "source": [
    "pred_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_val_y>thresh).astype(int))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375806/375806 [==============================] - 17s 44us/step\n"
     ]
    }
   ],
   "source": [
    "pred_test_y = model.predict([test_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.6076055160885917\n",
      "F1 score at threshold 0.11 is 0.615923757425531\n",
      "F1 score at threshold 0.12 is 0.6236484129752354\n",
      "F1 score at threshold 0.13 is 0.6305313666251999\n",
      "F1 score at threshold 0.14 is 0.6381305369734226\n",
      "F1 score at threshold 0.15 is 0.6441768544903024\n",
      "F1 score at threshold 0.16 is 0.6496268656716419\n",
      "F1 score at threshold 0.17 is 0.6546384429606479\n",
      "F1 score at threshold 0.18 is 0.6596848578016911\n",
      "F1 score at threshold 0.19 is 0.6639420036004476\n",
      "F1 score at threshold 0.2 is 0.6671919629666108\n",
      "F1 score at threshold 0.21 is 0.6706204834288562\n",
      "F1 score at threshold 0.22 is 0.6725779636253715\n",
      "F1 score at threshold 0.23 is 0.674715981456009\n",
      "F1 score at threshold 0.24 is 0.677931176591799\n",
      "F1 score at threshold 0.25 is 0.679363097096472\n",
      "F1 score at threshold 0.26 is 0.6814433531172857\n",
      "F1 score at threshold 0.27 is 0.681948424068768\n",
      "F1 score at threshold 0.28 is 0.683745109598585\n",
      "F1 score at threshold 0.29 is 0.6849448410123297\n",
      "F1 score at threshold 0.3 is 0.685732998580941\n",
      "F1 score at threshold 0.31 is 0.6869176911626881\n",
      "F1 score at threshold 0.32 is 0.687538230551076\n",
      "F1 score at threshold 0.33 is 0.6881032547699214\n",
      "F1 score at threshold 0.34 is 0.6881123633686357\n",
      "F1 score at threshold 0.35 is 0.6876036839997711\n",
      "F1 score at threshold 0.36 is 0.6877634694231102\n",
      "F1 score at threshold 0.37 is 0.6871645274212368\n",
      "F1 score at threshold 0.38 is 0.6871136751633602\n",
      "F1 score at threshold 0.39 is 0.6870917943237146\n",
      "F1 score at threshold 0.4 is 0.6862416107382551\n",
      "F1 score at threshold 0.41 is 0.6859529141197119\n",
      "F1 score at threshold 0.42 is 0.6841365829821024\n",
      "F1 score at threshold 0.43 is 0.6817033339495903\n",
      "F1 score at threshold 0.44 is 0.6797483336448016\n",
      "F1 score at threshold 0.45 is 0.676895987926047\n",
      "F1 score at threshold 0.46 is 0.6736574515411502\n",
      "F1 score at threshold 0.47 is 0.6720995893223819\n",
      "F1 score at threshold 0.48 is 0.6699928724162509\n",
      "F1 score at threshold 0.49 is 0.6678872686850192\n",
      "F1 score at threshold 0.5 is 0.6658301413287545\n",
      "Best threshold:  0.34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thresholds = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = metrics.f1_score(val_y, (pred_val_y > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = (pred_test_y > best_thresh).astype(int)\n",
    "out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "out_df['prediction'] = pred_test_y\n",
    "out_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
